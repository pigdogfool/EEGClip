import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import BartForConditionalGeneration, BertTokenizer, BertModel
from transformers.modeling_outputs import BaseModelOutput
import math
import numpy as np


class CNNPatchExtractor(nn.Module):
    """Two-layer CNN to convert EEG signals into patches"""
    
    def __init__(self, input_channels=66, patch_dim=256):
        super(CNNPatchExtractor, self).__init__()
        
        # First CNN layer
        self.conv1 = nn.Conv1d(
            in_channels=input_channels, 
            out_channels=128, 
            kernel_size=32, 
            stride=12,
            padding=8
        )
        self.bn1 = nn.BatchNorm1d(128)
        
        # Second CNN layer
        self.conv2 = nn.Conv1d(
            in_channels=128, 
            out_channels=patch_dim, 
            kernel_size=16, 
            stride=6,
            padding=4
        )
        self.bn2 = nn.BatchNorm1d(patch_dim)
        
        self.dropout = nn.Dropout(0.1)
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.dropout(x)
        
        x = self.conv2(x)
        x = self.bn2(x)
        x = F.relu(x)
        x = self.dropout(x)
        
        x = x.transpose(1, 2)
        return x


class PositionalEncoding(nn.Module):
    """Positional encoding for transformer"""
    
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           (-math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe)
        
    def forward(self, x):
        seq_len = x.size(1)
        return x + self.pe[:seq_len, :].unsqueeze(0)


class EEGTransformerEncoder(nn.Module):
    """Transformer encoder for EEG patches"""
    
    def __init__(self, patch_dim=256, num_heads=8, num_layers=6, 
                 ff_dim=1024, dropout=0.1):
        super(EEGTransformerEncoder, self).__init__()
        
        self.patch_dim = patch_dim
        self.pos_encoding = PositionalEncoding(patch_dim)
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=patch_dim,
            nhead=num_heads,
            dim_feedforward=ff_dim,
            dropout=dropout,
            batch_first=True
        )
        
        self.transformer_encoder = nn.TransformerEncoder(
            encoder_layer, 
            num_layers=num_layers
        )
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x, src_key_padding_mask=None):
        x = self.pos_encoding(x)
        x = self.dropout(x)
        
        encoded = self.transformer_encoder(
            x, 
            src_key_padding_mask=src_key_padding_mask
        )
        
        return encoded


class TextEncoder(nn.Module):
    """æ–‡æœ¬ç¼–ç å™¨ï¼Œä½¿ç”¨BARTç¼–ç å™¨æå–æ–‡æœ¬ç‰¹å¾"""
    
    def __init__(self, bart_model_name="fnlp/bart-base-chinese", hidden_dim=768):
        super(TextEncoder, self).__init__()
        
        # âœ… ä½¿ç”¨BARTç¼–ç å™¨è€Œä¸æ˜¯BERT
        bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)
        self.bart_encoder = bart_model.model.encoder
        self.hidden_dim = hidden_dim
        
        # è·å–BARTçš„é…ç½®
        self.config = bart_model.config
        
        print(f"ğŸ”§ æ–‡æœ¬ç¼–ç å™¨ä½¿ç”¨: {bart_model_name}")
        print(f"   BARTç¼–ç å™¨éšè—ç»´åº¦: {self.config.d_model}")
        
    def forward(self, input_ids, attention_mask=None):
        """
        Args:
            input_ids: (batch_size, seq_len)
            attention_mask: (batch_size, seq_len)
        
        Returns:
            text_features: (batch_size, hidden_dim) - å¥å­çº§åˆ«çš„ç‰¹å¾
        """
        if attention_mask is None:
            # åˆ›å»ºattention_maskï¼šépad_tokençš„ä½ç½®ä¸º1ï¼Œpad_tokençš„ä½ç½®ä¸º0
            attention_mask = (input_ids != self.config.pad_token_id).long()
        
        # âœ… ä½¿ç”¨BARTç¼–ç å™¨
        encoder_outputs = self.bart_encoder(
            input_ids=input_ids,
            attention_mask=attention_mask,
            return_dict=True
        )
        
        # è·å–ç¼–ç å™¨çš„è¾“å‡º
        last_hidden_state = encoder_outputs.last_hidden_state  # (batch_size, seq_len, hidden_dim)
        
        # âœ… ä½¿ç”¨attention maskè¿›è¡Œå¹³å‡æ± åŒ–
        if attention_mask is not None:
            # æ‰©å±•attention_maskçš„ç»´åº¦ä»¥åŒ¹é…hidden_state
            mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()
            
            # å¯¹æœ‰æ•ˆtokenè¿›è¡ŒåŠ æƒå¹³å‡
            sum_embeddings = torch.sum(last_hidden_state * mask_expanded, dim=1)  # (batch_size, hidden_dim)
            sum_mask = torch.clamp(torch.sum(mask_expanded, dim=1), min=1e-9)  # (batch_size, hidden_dim)
            sentence_features = sum_embeddings / sum_mask  # (batch_size, hidden_dim)
        else:
            # å¦‚æœæ²¡æœ‰maskï¼Œç›´æ¥å¹³å‡
            sentence_features = torch.mean(last_hidden_state, dim=1)
        
        return sentence_features


class ContrastiveEEGTextModel(nn.Module):
    """å¯¹æ¯”å­¦ä¹ çš„EEG-æ–‡æœ¬æ¨¡å‹"""
    
    def __init__(self, 
                 bart_model_name="fnlp/bart-base-chinese",
                 patch_dim=256,
                 feature_dim=768,
                 target_channels=66, 
                 target_length=4000,
                 temperature=0.07):
        super(ContrastiveEEGTextModel, self).__init__()
        
        self.target_channels = target_channels
        self.target_length = target_length
        self.feature_dim = feature_dim
        self.temperature = temperature
        self.patch_dim = patch_dim
        print(f"ğŸ—ï¸  åˆå§‹åŒ–æ¨¡å‹ç»„ä»¶...")
        
        # EEGå¤„ç†ç»„ä»¶
        print(f"  åˆå§‹åŒ–CNNç‰¹å¾æå–å™¨...")
        self.patch_extractor = CNNPatchExtractor(
            input_channels=target_channels, 
            patch_dim=patch_dim
        )
        self.eeg_encoder = EEGTransformerEncoder(
            patch_dim=patch_dim,
            num_heads=8,
            num_layers=6
        )
        
        # âœ… åˆå§‹åŒ–æ–‡æœ¬ç¼–ç å™¨å¹¶ç«‹å³å†»ç»“
        self.text_encoder = TextEncoder(
            bart_model_name=bart_model_name,
            hidden_dim=feature_dim
        )
        
        # â„ï¸ ç«‹å³å†»ç»“æ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰å‚æ•°
        print("â„ï¸ æ°¸ä¹…å†»ç»“æ–‡æœ¬ç¼–ç å™¨å‚æ•°...")
        for param in self.text_encoder.parameters():
            param.requires_grad = False
        
        frozen_text_params = sum(p.numel() for p in self.text_encoder.parameters())
        print(f"ğŸ”’ å·²å†»ç»“æ–‡æœ¬ç¼–ç å™¨å‚æ•°: {frozen_text_params:,}")

        # æŠ•å½±å±‚
        self.eeg_projection = nn.Sequential(
            nn.Linear(patch_dim, self.feature_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(self.feature_dim, self.feature_dim),
            nn.LayerNorm(self.feature_dim)
        )

        self.text_projection = nn.Sequential(
            nn.Linear(self.feature_dim, self.feature_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(self.feature_dim, self.feature_dim),
            nn.LayerNorm(self.feature_dim)
        )
        
        # âœ… åˆå§‹åŒ–BARTç”Ÿæˆæ¨¡å‹ï¼ˆç”¨äºé˜¶æ®µ2ï¼‰
        print(f"  åˆå§‹åŒ–BARTç”Ÿæˆæ¨¡å‹...")
        bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)
        self.bart = bart_model
        
        # â„ï¸ ç«‹å³å†»ç»“BARTç¼–ç å™¨ï¼ˆæˆ‘ä»¬ç”¨EEGç¼–ç å™¨æ›¿ä»£ï¼‰
        print("â„ï¸ æ°¸ä¹…å†»ç»“BARTç¼–ç å™¨...")
        for param in self.bart.model.encoder.parameters():
            param.requires_grad = False
        
        frozen_bart_encoder_params = sum(p.numel() for p in self.bart.model.encoder.parameters())
        print(f"ğŸ”’ å·²å†»ç»“BARTç¼–ç å™¨å‚æ•°: {frozen_bart_encoder_params:,}")

    def configure_for_stage1(self):
        """é…ç½®é˜¶æ®µ1è®­ç»ƒå‚æ•°ï¼šè®­ç»ƒEEGç¼–ç å™¨ï¼Œå†»ç»“BARTè§£ç å™¨"""
        print("ğŸ”§ é…ç½®é˜¶æ®µ1å‚æ•°çŠ¶æ€...")
        
        # âœ… å†»ç»“BARTçš„æ‰€æœ‰å‚æ•°
        for param in self.bart.parameters():
            param.requires_grad = False
        print("ğŸ”’ å†»ç»“BARTè§£ç å™¨")
        
        # âœ… è§£å†»EEGç¼–ç å™¨å‚æ•°
        for param in self.patch_extractor.parameters():
            param.requires_grad = True
        print(f"ğŸ”“ è§£å†»CNNç‰¹å¾æå–å™¨: {sum(p.numel() for p in self.patch_extractor.parameters()):,} å‚æ•°")
        
        for param in self.eeg_encoder.parameters():
            param.requires_grad = True
        print(f"ğŸ”“ è§£å†»EEG Transformerç¼–ç å™¨: {sum(p.numel() for p in self.eeg_encoder.parameters()):,} å‚æ•°")
        
        for param in self.eeg_projection.parameters():
            param.requires_grad = True
        print(f"ğŸ”“ è§£å†»EEGæŠ•å½±å±‚: {sum(p.numel() for p in self.eeg_projection.parameters()):,} å‚æ•°")
        
        # â„ï¸ ç¡®ä¿æ–‡æœ¬ç¼–ç å™¨ä¿æŒæ°¸ä¹…å†»ç»“
        for param in self.text_encoder.parameters():
            param.requires_grad = False
        print(f"â„ï¸ ç¡®è®¤æ–‡æœ¬ç¼–ç å™¨æ°¸ä¹…å†»ç»“: {sum(p.numel() for p in self.text_encoder.parameters()):,} å‚æ•°")
        
        # âœ… æ–‡æœ¬æŠ•å½±å±‚éœ€è¦è®­ç»ƒ
        for param in self.text_projection.parameters():
            param.requires_grad = True
        print(f"ğŸ”“ è§£å†»æ–‡æœ¬æŠ•å½±å±‚: {sum(p.numel() for p in self.text_projection.parameters()):,} å‚æ•°")
        
        # âœ… ç»Ÿè®¡é˜¶æ®µ1é¢„æœŸå‚æ•°
        stage1_params = (
            sum(p.numel() for p in self.patch_extractor.parameters()) +
            sum(p.numel() for p in self.eeg_encoder.parameters()) +
            sum(p.numel() for p in self.eeg_projection.parameters()) +
            sum(p.numel() for p in self.text_projection.parameters())
        )
        print(f"ğŸ“Š é˜¶æ®µ1é¢„æœŸå¯è®­ç»ƒå‚æ•°æ€»è®¡: {stage1_params:,}")
    
    def configure_for_stage2(self, freeze_decoder=False, freeze_eeg_encoder=False):
        """é…ç½®é˜¶æ®µ2è®­ç»ƒå‚æ•°"""
        print("ğŸ”§ é…ç½®é˜¶æ®µ2è®­ç»ƒå‚æ•°...")
        
        if freeze_decoder:
            print("ğŸ”’ å†»ç»“BARTè§£ç å™¨...")
            # å†»ç»“BARTè§£ç å™¨å’ŒLMå¤´
            for param in self.bart.model.decoder.parameters():
                param.requires_grad = False
            for param in self.bart.lm_head.parameters():
                param.requires_grad = False
            
            print("ğŸ”“ è§£å†»EEGç¼–ç å™¨ç»„ä»¶...")
            # è§£å†»ç¼–ç å™¨
            for param in self.patch_extractor.parameters():
                param.requires_grad = True
            for param in self.eeg_encoder.parameters():
                param.requires_grad = True
            for param in self.eeg_projection.parameters():
                param.requires_grad = True
                
        elif freeze_eeg_encoder:
            print("ğŸ”’ å†»ç»“EEGç¼–ç å™¨ç»„ä»¶...")
            # å†»ç»“EEGç¼–ç å™¨
            for param in self.patch_extractor.parameters():
                param.requires_grad = False
            for param in self.eeg_encoder.parameters():
                param.requires_grad = False
            for param in self.eeg_projection.parameters():
                param.requires_grad = False
                
            print("ğŸ”“ è§£å†»BARTè§£ç å™¨...")
            # è§£å†»BARTè§£ç å™¨å’ŒLMå¤´
            for param in self.bart.model.decoder.parameters():
                param.requires_grad = True
            for param in self.bart.lm_head.parameters():
                param.requires_grad = True
                
        else:
            print("ğŸ”“ è§£å†»EEGç¼–ç å™¨å’ŒBARTè§£ç å™¨è¿›è¡Œè”åˆè®­ç»ƒ...")
            # è§£å†»EEGç¼–ç å™¨
            for param in self.patch_extractor.parameters():
                param.requires_grad = True
            for param in self.eeg_encoder.parameters():
                param.requires_grad = True
            for param in self.eeg_projection.parameters():
                param.requires_grad = True
            # è§£å†»BARTè§£ç å™¨å’ŒLMå¤´
            for param in self.bart.model.decoder.parameters():
                param.requires_grad = True
            for param in self.bart.lm_head.parameters():
                param.requires_grad = True
        
        # â„ï¸ ç¡®ä¿BARTç¼–ç å™¨æ°¸è¿œä¿æŒå†»ç»“ï¼ˆå› ä¸ºæˆ‘ä»¬ç”¨EEGç¼–ç å™¨æ›¿ä»£ï¼‰
        print("â„ï¸ ç¡®è®¤BARTç¼–ç å™¨æ°¸ä¹…å†»ç»“...")
        for param in self.bart.model.encoder.parameters():
            param.requires_grad = False
                
        # â„ï¸ ç¡®ä¿æ–‡æœ¬ç¼–ç å™¨çš„æ‰€æœ‰ç»„ä»¶æ°¸è¿œä¿æŒå†»ç»“
        print("â„ï¸ ç¡®è®¤æ–‡æœ¬ç¼–ç å™¨æ°¸ä¹…å†»ç»“...")
        for param in self.text_encoder.parameters():
            param.requires_grad = False
        
        # â„ï¸ åœ¨é˜¶æ®µ2ä¸­ä¹Ÿå†»ç»“æ–‡æœ¬æŠ•å½±å±‚ï¼ˆä¿æŒé¢„è®­ç»ƒç‰¹å¾ï¼‰
        print("â„ï¸ å†»ç»“æ–‡æœ¬æŠ•å½±å±‚ï¼ˆä¿æŒé¢„è®­ç»ƒç‰¹å¾ï¼‰...")
        for param in self.text_projection.parameters():
            param.requires_grad = False
        
        # âœ… éªŒè¯å†»ç»“çŠ¶æ€
        frozen_text_params = sum(p.numel() for p in self.text_encoder.parameters())
        frozen_text_proj_params = sum(p.numel() for p in self.text_projection.parameters())
        frozen_bart_encoder_params = sum(p.numel() for p in self.bart.model.encoder.parameters())
        
        print(f"â„ï¸ éªŒè¯å†»ç»“çŠ¶æ€:")
        print(f"   æ–‡æœ¬ç¼–ç å™¨: {frozen_text_params:,} å‚æ•° (æ°¸ä¹…å†»ç»“)")
        print(f"   æ–‡æœ¬æŠ•å½±å±‚: {frozen_text_proj_params:,} å‚æ•° (é˜¶æ®µ2å†»ç»“)")
        print(f"   BARTç¼–ç å™¨: {frozen_bart_encoder_params:,} å‚æ•° (æ°¸ä¹…å†»ç»“)")
        
        # âœ… ç»Ÿè®¡é˜¶æ®µ2é¢„æœŸå‚æ•°
        if freeze_eeg_encoder:
            stage2_params = (
                sum(p.numel() for p in self.bart.model.decoder.parameters() if p.requires_grad) +
                sum(p.numel() for p in self.bart.lm_head.parameters() if p.requires_grad)
            )
        elif freeze_decoder:
            stage2_params = (
                sum(p.numel() for p in self.patch_extractor.parameters() if p.requires_grad) +
                sum(p.numel() for p in self.eeg_encoder.parameters() if p.requires_grad) +
                sum(p.numel() for p in self.eeg_projection.parameters() if p.requires_grad)
            )
        else:
            stage2_params = (
                sum(p.numel() for p in self.patch_extractor.parameters() if p.requires_grad) +
                sum(p.numel() for p in self.eeg_encoder.parameters() if p.requires_grad) +
                sum(p.numel() for p in self.eeg_projection.parameters() if p.requires_grad) +
                sum(p.numel() for p in self.bart.model.decoder.parameters() if p.requires_grad) +
                sum(p.numel() for p in self.bart.lm_head.parameters() if p.requires_grad)
            )
        print(f"ğŸ“Š é˜¶æ®µ2é¢„æœŸå¯è®­ç»ƒå‚æ•°æ€»è®¡: {stage2_params:,}")
    
    def get_trainable_parameters_stage2(self, freeze_decoder=False, freeze_eeg_encoder=False):
        """è·å–é˜¶æ®µ2çš„å¯è®­ç»ƒå‚æ•°é…ç½®"""
        param_groups = []
        
        if freeze_decoder and freeze_eeg_encoder:
            # é”™è¯¯é…ç½®ï¼šä¸¤è€…éƒ½å†»ç»“
            print("âŒ é”™è¯¯é…ç½®ï¼šç¼–ç å™¨å’Œè§£ç å™¨éƒ½è¢«å†»ç»“!")
            return []
            
        elif freeze_decoder:
            # å†»ç»“BARTè§£ç å™¨ï¼Œåªè®­ç»ƒEEGç¼–ç å™¨
            param_groups = [
                {'params': [p for p in self.patch_extractor.parameters() if p.requires_grad], 
                 'lr': 5e-5, 'name': 'patch_extractor'},
                {'params': [p for p in self.eeg_encoder.parameters() if p.requires_grad], 
                 'lr': 5e-5, 'name': 'eeg_encoder'},
                {'params': [p for p in self.eeg_projection.parameters() if p.requires_grad], 
                 'lr': 1e-4, 'name': 'eeg_projection'},
            ]
            
        elif freeze_eeg_encoder:
            # âœ… å†»ç»“EEGç¼–ç å™¨ï¼Œåªè®­ç»ƒBARTè§£ç å™¨
            param_groups = [
                # âœ… åªè®­ç»ƒBARTè§£ç å™¨å’ŒLMå¤´
                {'params': [p for p in self.bart.model.decoder.parameters() if p.requires_grad], 
                 'lr': 1e-4, 'name': 'bart_decoder'},
                {'params': [p for p in self.bart.lm_head.parameters() if p.requires_grad], 
                 'lr': 2e-4, 'name': 'bart_lm_head'},
            ]
            
        else:
            # è”åˆè®­ç»ƒEEGç¼–ç å™¨å’ŒBARTè§£ç å™¨
            param_groups = [
                # EEGç¼–ç å™¨å‚æ•°
                {'params': [p for p in self.patch_extractor.parameters() if p.requires_grad], 
                 'lr': 2e-5, 'name': 'patch_extractor'},
                {'params': [p for p in self.eeg_encoder.parameters() if p.requires_grad], 
                 'lr': 2e-5, 'name': 'eeg_encoder'},
                {'params': [p for p in self.eeg_projection.parameters() if p.requires_grad], 
                 'lr': 5e-5, 'name': 'eeg_projection'},
                
                # âœ… åªæœ‰BARTè§£ç å™¨å’ŒLMå¤´å‚ä¸è®­ç»ƒ
                {'params': [p for p in self.bart.model.decoder.parameters() if p.requires_grad], 
                 'lr': 1e-4, 'name': 'bart_decoder'},
                {'params': [p for p in self.bart.lm_head.parameters() if p.requires_grad], 
                 'lr': 2e-4, 'name': 'bart_lm_head'},
            ]
        
        # è¿‡æ»¤æ‰ç©ºçš„å‚æ•°ç»„
        filtered_groups = []
        for group in param_groups:
            if len(group['params']) > 0:
                filtered_groups.append(group)
                print(f"âœ… å‚æ•°ç»„ '{group['name']}': {len(group['params'])} ä¸ªå‚æ•°, lr={group['lr']}")
        
        # â„ï¸ éªŒè¯æ–‡æœ¬ç¼–ç å™¨æ°¸ä¹…å†»ç»“
        text_encoder_trainable = any(p.requires_grad for p in self.text_encoder.parameters())
        if text_encoder_trainable:
            print("âŒ è­¦å‘Šï¼šæ£€æµ‹åˆ°æ–‡æœ¬ç¼–ç å™¨ä¸­æœ‰å¯è®­ç»ƒå‚æ•°ï¼")
        else:
            print("âœ… ç¡®è®¤ï¼šæ–‡æœ¬ç¼–ç å™¨æ‰€æœ‰å‚æ•°å·²æ°¸ä¹…å†»ç»“")
        
        return filtered_groups

    def process_batch_eeg(self, eeg_batch):
        """å¤„ç†EEGæ•°æ®"""
        # ğŸ”§ è·å–æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡
        device = next(self.parameters()).device
        
        if isinstance(eeg_batch, list):
            batch_size = len(eeg_batch)
            # ğŸ”§ åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šåˆ›å»ºtensor
            processed_eeg = torch.zeros(batch_size, self.target_channels, self.target_length, device=device)
            original_lengths = []
            
            for i, eeg in enumerate(eeg_batch):
                if isinstance(eeg, np.ndarray):
                    eeg = torch.from_numpy(eeg).float()
                
                # ğŸ”§ ç¡®ä¿è¾“å…¥EEGåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
                eeg = eeg.to(device)
                
                current_channels, current_length = eeg.shape
                original_lengths.append(current_length)
                
                # å¤„ç†é€šé“æ•°
                if current_channels != self.target_channels:
                    if current_channels < self.target_channels:
                        # ğŸ”§ åœ¨æ­£ç¡®è®¾å¤‡ä¸Šåˆ›å»ºpadding
                        padding_channels = torch.zeros(self.target_channels - current_channels, current_length, device=device)
                        eeg = torch.cat([eeg, padding_channels], dim=0)
                    else:
                        eeg = eeg[:self.target_channels, :]
                
                # å¤„ç†æ—¶é—´é•¿åº¦
                if current_length > self.target_length:
                    processed_eeg[i] = eeg[:, :self.target_length]
                    original_lengths[i] = self.target_length
                else:
                    processed_eeg[i, :, :current_length] = eeg
            
            return processed_eeg, original_lengths
        else:
            # å¦‚æœå·²ç»æ˜¯tensorï¼Œç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            batch_size = eeg_batch.size(0)
            eeg_batch = eeg_batch.to(device)
            return eeg_batch, [self.target_length] * batch_size
    
    def calculate_patch_lengths(self, original_lengths):
        """è®¡ç®—patché•¿åº¦"""
        patch_lengths = []
        for length in original_lengths:
            effective_length = min(length, self.target_length)
            after_conv1 = (effective_length + 16 - 32) // 12 + 1
            after_conv2 = (after_conv1 + 8 - 16) // 6 + 1
            patch_length = max(1, after_conv2)
            patch_lengths.append(patch_length)
        return patch_lengths

    def create_eeg_mask(self, patch_lengths, max_patches):
        """åˆ›å»ºEEG mask"""
        # ğŸ”§ è·å–æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡
        device = next(self.parameters()).device
        
        batch_size = len(patch_lengths)
        # ğŸ”§ åœ¨æ­£ç¡®è®¾å¤‡ä¸Šåˆ›å»ºmask
        mask = torch.zeros(batch_size, max_patches, dtype=torch.bool, device=device)
        
        for i, length in enumerate(patch_lengths):
            if length < max_patches:
                mask[i, length:] = True
                
        return mask
    
    def encode_eeg(self, eeg_data):
        """ç¼–ç EEGæ•°æ®åˆ°ç‰¹å¾ç©ºé—´"""
        processed_eeg, original_lengths = self.process_batch_eeg(eeg_data)
        patch_lengths = self.calculate_patch_lengths(original_lengths)
        
        # æå–patches
        eeg_patches = self.patch_extractor(processed_eeg)
        seq_len = eeg_patches.size(1)
        
        # åˆ›å»ºmask
        eeg_mask = self.create_eeg_mask(patch_lengths, seq_len)
        eeg_mask = eeg_mask.to(processed_eeg.device)
        
        # Transformerç¼–ç 
        encoded_eeg = self.eeg_encoder(
            eeg_patches, 
            src_key_padding_mask=eeg_mask
        )
        
        # âœ… ç§»é™¤å¹³å‡æ± åŒ–æ­¥éª¤ï¼Œç›´æ¥è¿”å›åºåˆ—ç‰¹å¾
        return encoded_eeg, eeg_mask, patch_lengths

    def encode_text(self, text_batch, tokenizer, max_length=32):
        """ç¼–ç æ–‡æœ¬æ•°æ®åˆ°ç‰¹å¾ç©ºé—´"""
        # âœ… ä½¿ç”¨BART tokenizerè€Œä¸æ˜¯BERT tokenizer
        encodings = tokenizer(
            text_batch,
            padding='max_length',
            max_length=max_length,
            truncation=True,
            return_tensors='pt'
        )
        
        input_ids = encodings['input_ids']
        attention_mask = encodings['attention_mask'] 
        
        # ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        device = next(self.text_encoder.parameters()).device
        input_ids = input_ids.to(device)
        attention_mask = attention_mask.to(device)
        
        # âœ… ä½¿ç”¨BARTç¼–ç å™¨ç¼–ç æ–‡æœ¬
        sentence_features = self.text_encoder(
            input_ids, 
            attention_mask=attention_mask 
        )
        
        # æŠ•å½±åˆ°å¯¹æ¯”å­¦ä¹ ç©ºé—´
        text_features = self.text_projection(sentence_features)
        
        return text_features, input_ids, attention_mask
    
    def contrastive_loss(self, encoded_eeg, eeg_mask, patch_lengths, text_features, text_data):
        """è®¡ç®—å¯¹æ¯”æŸå¤± - è€ƒè™‘é‡å¤å¥å­"""
        # ğŸ”§ è·å–è®¾å¤‡
        device = encoded_eeg.device
        
        # EEGç‰¹å¾å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        eeg_features = []
        for i, length in enumerate(patch_lengths):
            if length > 0:
                valid_features = encoded_eeg[i, :length, :].mean(dim=0)
            else:
                valid_features = encoded_eeg[i, 0, :]
            eeg_features.append(valid_features)
        
        eeg_features = torch.stack(eeg_features)
        eeg_features = self.eeg_projection(eeg_features)
        
        # L2æ ‡å‡†åŒ–
        eeg_features = F.normalize(eeg_features, p=2, dim=1)
        text_features = F.normalize(text_features, p=2, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        similarity_matrix = torch.matmul(eeg_features, text_features.T) / self.temperature
        batch_size = eeg_features.size(0)
        
        # âœ… åˆ›å»ºè€ƒè™‘é‡å¤å¥å­çš„æ ‡ç­¾çŸ©é˜µ - åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        positive_mask = torch.zeros(batch_size, batch_size, dtype=torch.bool, device=device)
        
        # æ ‡è®°æ‰€æœ‰æ­£æ ·æœ¬å¯¹ï¼ˆç›¸åŒå¥å­ï¼‰
        for i in range(batch_size):
            for j in range(batch_size):
                if text_data[i] == text_data[j]:  # ç›¸åŒå¥å­
                    positive_mask[i, j] = True
        
        # âœ… ä½¿ç”¨å¤šæ ‡ç­¾å¯¹æ¯”æŸå¤±
        losses = []
        for i in range(batch_size):
            # å¯¹äºæ¯ä¸ªEEGï¼Œæ‰¾åˆ°æ‰€æœ‰æ­£æ ·æœ¬
            positive_indices = torch.where(positive_mask[i])[0]
            negative_indices = torch.where(~positive_mask[i])[0]
            
            if len(positive_indices) > 0 and len(negative_indices) > 0:
                # æ­£æ ·æœ¬çš„logits
                pos_logits = similarity_matrix[i][positive_indices]
                # è´Ÿæ ·æœ¬çš„logits  
                neg_logits = similarity_matrix[i][negative_indices]
                
                # InfoNCEæŸå¤±ï¼šlog(sum(exp(pos)) / (sum(exp(pos)) + sum(exp(neg))))
                pos_exp = torch.exp(pos_logits)
                neg_exp = torch.exp(neg_logits)
                
                loss_i = -torch.log(pos_exp.sum() / (pos_exp.sum() + neg_exp.sum()))
                losses.append(loss_i)
        
        if losses:
            contrastive_loss = torch.stack(losses).mean()
        else:
            # é€€å›åˆ°åŸå§‹æ–¹æ³• - ç¡®ä¿labelsåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            labels = torch.arange(batch_size, device=device)
            contrastive_loss = F.cross_entropy(similarity_matrix, labels)
        
        return contrastive_loss
    
    def forward(self, eeg_data, text_data=None, tokenizer=None):
        """
        å‰å‘ä¼ æ’­ - æ”¯æŒä¸‰ç§æ¨¡å¼
        """
        if text_data is None or tokenizer is None:
            raise ValueError("å¯¹æ¯”å­¦ä¹ æ¨¡å¼éœ€è¦æä¾›text_dataå’Œtokenizer")
            
            # âœ… è·å–åºåˆ—ç‰¹å¾è€Œä¸æ˜¯æ± åŒ–ç‰¹å¾
        encoded_eeg, eeg_mask, patch_lengths = self.encode_eeg(eeg_data)
        text_features, input_ids, attention_mask = self.encode_text(text_data, tokenizer)
            
            # âœ… åœ¨å¯¹æ¯”æŸå¤±ä¸­è¿›è¡Œæ± åŒ–
        loss = self.contrastive_loss(encoded_eeg, eeg_mask, patch_lengths, text_features, text_data)
            
        return {
            'loss': loss,
            'encoded_eeg': encoded_eeg,
            'eeg_mask': eeg_mask,
            'patch_lengths': patch_lengths,
            'text_features': text_features
        }

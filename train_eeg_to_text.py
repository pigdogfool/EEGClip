import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, Subset
import numpy as np
import pandas as pd
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import logging
import json
from datetime import datetime
from pathlib import Path

from eeg_to_text_model_contrastive import create_contrastive_model 

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EEGTextDataset(Dataset):
    """EEGå’Œæ–‡æœ¬é…å¯¹æ•°æ®é›†"""
    
    def __init__(self, csv_file, eeg_dir, tokenizer, max_text_length=32):
        """
        Args:
            csv_file: CSVæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«idå’Œsentenceåˆ—
            eeg_dir: EEGæ•°æ®ç›®å½•è·¯å¾„
            tokenizer: æ–‡æœ¬tokenizer
            max_text_length: æœ€å¤§æ–‡æœ¬é•¿åº¦
        """
        self.data = pd.read_csv(csv_file)
        self.eeg_dir = eeg_dir
        self.tokenizer = tokenizer
        self.max_text_length = max_text_length
        
        # âœ… é¦–å…ˆæ£€æŸ¥EEGç›®å½•ä¸‹çš„å®é™…æ–‡ä»¶
        logger.info(f"æ£€æŸ¥EEGç›®å½•: {eeg_dir}")
        eeg_files = [f for f in os.listdir(eeg_dir) if f.endswith('.npy')]
        logger.info(f"æ‰¾åˆ° {len(eeg_files)} ä¸ªEEGæ–‡ä»¶")
        if len(eeg_files) <= 10:
            logger.info(f"EEGæ–‡ä»¶ç¤ºä¾‹: {eeg_files}")
        else:
            logger.info(f"å‰10ä¸ªEEGæ–‡ä»¶: {eeg_files[:10]}")
        
        # âœ… æ£€æŸ¥CSVæ•°æ®
        logger.info(f"CSVæ•°æ®æ€»æ•°: {len(self.data)}")
        logger.info(f"IDèŒƒå›´: {self.data['id'].min()} - {self.data['id'].max()}")
        unique_ids = self.data['id'].nunique()
        logger.info(f"å”¯ä¸€IDæ•°é‡: {unique_ids}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ID
        if unique_ids != len(self.data):
            logger.warning(f"å‘ç°é‡å¤ID! æ€»è¡Œæ•°: {len(self.data)}, å”¯ä¸€ID: {unique_ids}")
            duplicates = self.data[self.data.duplicated(['id'], keep=False)]
            logger.info(f"é‡å¤IDç¤ºä¾‹: {duplicates['id'].unique()[:10]}")
        
        # è¿‡æ»¤æ‰æ²¡æœ‰å¯¹åº”EEGæ–‡ä»¶çš„æ•°æ®
        self.valid_data = []
        not_found_ids = []
        
        for idx, row in self.data.iterrows():
            # âœ… å°è¯•å¤šç§å¯èƒ½çš„æ–‡ä»¶åæ¨¡å¼
            possible_patterns = [
                f"preprocessed_{row['id']}_raw_300_0328.npy",
                f"preprocessed_{row['id']}.npy",
                f"{row['id']}_raw_300_0328.npy",
                f"{row['id']}.npy",
            ]
            
            eeg_path = None
            for pattern in possible_patterns:
                test_path = os.path.join(eeg_dir, pattern)
                if os.path.exists(test_path):
                    eeg_path = test_path
                    break
            
            if eeg_path:
                self.valid_data.append({
                    'id': row['id'],
                    'sentence': row['sentence'],
                    'eeg_path': eeg_path
                })
            else:
                not_found_ids.append(row['id'])
        
        logger.info(f"æ‰¾åˆ° {len(self.valid_data)} ä¸ªæœ‰æ•ˆçš„EEG-æ–‡æœ¬é…å¯¹")
        logger.info(f"æœªæ‰¾åˆ°EEGæ–‡ä»¶çš„IDæ•°é‡: {len(not_found_ids)}")
        
        if len(not_found_ids) > 0:
            logger.warning(f"å‰10ä¸ªæœªæ‰¾åˆ°çš„ID: {not_found_ids[:10]}")
            # æ£€æŸ¥è¿™äº›IDå¯¹åº”çš„æœŸæœ›æ–‡ä»¶å
            logger.info("æœŸæœ›çš„æ–‡ä»¶åç¤ºä¾‹:")
            for i, missing_id in enumerate(not_found_ids[:3]):
                expected_file = f"preprocessed_{missing_id}_raw_300_0328.npy"
                logger.info(f"  ID {missing_id} â†’ {expected_file}")
        
        if len(self.valid_data) == 0:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„EEG-æ–‡æœ¬é…å¯¹!")
            logger.info("è¯·æ£€æŸ¥ï¼š")
            logger.info("1. EEGæ–‡ä»¶å‘½åæ ¼å¼æ˜¯å¦æ­£ç¡®")
            logger.info("2. CSVä¸­çš„IDæ˜¯å¦ä¸EEGæ–‡ä»¶ååŒ¹é…")
            logger.info("3. æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            
        # âœ… æ£€æŸ¥æœ‰æ•ˆæ•°æ®çš„åˆ†å¸ƒ
        if len(self.valid_data) > 0:
            valid_ids = [item['id'] for item in self.valid_data]
            logger.info(f"æœ‰æ•ˆIDèŒƒå›´: {min(valid_ids)} - {max(valid_ids)}")
            logger.info(f"æœ‰æ•ˆæ•°æ®ç¤ºä¾‹:")
            for i, item in enumerate(self.valid_data[:3]):
                logger.info(f"  ID: {item['id']}, æ–‡æœ¬: {item['sentence'][:30]}...")
                logger.info(f"  EEGæ–‡ä»¶: {os.path.basename(item['eeg_path'])}")
    
    def __len__(self):
        return len(self.valid_data)
    
    def __getitem__(self, idx):
        """è¿”å›å•ä¸ªæ•°æ®æ ·æœ¬"""
        item = self.valid_data[idx]
        
        # åŠ è½½EEGæ•°æ®
        try:
            eeg_data = np.load(item['eeg_path'])
            eeg_data = eeg_data.astype(np.float32)
            
            # âœ… æ£€æŸ¥EEGæ•°æ®å½¢çŠ¶
            if idx < 3:  # åªå¯¹å‰å‡ ä¸ªæ ·æœ¬æ‰“å°ä¿¡æ¯
                logger.info(f"æ ·æœ¬ {idx}: EEGå½¢çŠ¶ {eeg_data.shape}, æ–‡æœ¬: {item['sentence'][:30]}...")
            
            # æ¯ä¸ªé€šé“ç‹¬ç«‹æ ‡å‡†åŒ–
            for ch in range(eeg_data.shape[0]):
                mean = np.mean(eeg_data[ch])
                std = np.std(eeg_data[ch])
                if std > 0:
                    eeg_data[ch] = (eeg_data[ch] - mean) / std
        
        except Exception as e:
            logger.error(f"åŠ è½½EEGæ–‡ä»¶å¤±è´¥: {item['eeg_path']}, é”™è¯¯: {e}")
            eeg_data = np.zeros((66, 4000), dtype=np.float32)
        
        text = item['sentence']
        
        return {
            'eeg': torch.from_numpy(eeg_data),
            'text': text,
            'id': item['id']
        }

def collate_fn(batch):
    """æ‰¹å¤„ç†å‡½æ•°ï¼Œå¤„ç†ä¸åŒé•¿åº¦çš„EEGæ•°æ®"""
    eeg_list = [item['eeg'] for item in batch]
    text_list = [item['text'] for item in batch]
    ids = [item['id'] for item in batch]
    
    return {
        'eeg': eeg_list,
        'text': text_list,
        'ids': ids
    }

class TwoStageTrainer:
    """ä¸¤é˜¶æ®µè®­ç»ƒå™¨ï¼šé¢„è®­ç»ƒç¼–ç å™¨ â†’ å†»ç»“ç¼–ç å™¨å¾®è°ƒè§£ç å™¨"""
    
    def __init__(self, model, tokenizer, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.model = model.to(device)
        self.tokenizer = tokenizer
        self.device = device
        
        # è®­ç»ƒå†å²è®°å½•
        self.stage1_losses = []
        self.stage2_losses = []
    
    def stage1_contrastive_training(self, train_loader, val_loader, epochs=30, 
                                   learning_rate=1e-4, save_path="stage1_encoder.pth"):
        """é˜¶æ®µ1: å¯¹æ¯”å­¦ä¹ è®­ç»ƒç¼–ç å™¨"""
        print("\n" + "="*60)
        print("ğŸ”¥ é˜¶æ®µ1: å¯¹æ¯”å­¦ä¹ è®­ç»ƒç¼–ç å™¨")
        print("âš ï¸  æ³¨æ„: æ­¤é˜¶æ®µåªè®­ç»ƒç¼–ç å™¨ï¼Œå†»ç»“BARTè§£ç å™¨")
        print("="*60)
        
        # âœ… ä½¿ç”¨æ¨¡å‹çš„é…ç½®æ–¹æ³•è€Œä¸æ˜¯æ‰‹åŠ¨é…ç½®
        print("ğŸ”§ é…ç½®é˜¶æ®µ1å‚æ•°çŠ¶æ€...")
        
        # é˜¶æ®µ1é…ç½®ï¼šè®­ç»ƒEEGç¼–ç å™¨ï¼Œå†»ç»“BARTè§£ç å™¨
        self.model.configure_for_stage1()
        
        # âœ… æ”¶é›†å¯è®­ç»ƒå‚æ•°
        trainable_params = [p for p in self.model.parameters() if p.requires_grad]
        
        # âœ… è¯¦ç»†æ‰“å°å‚æ•°ç»Ÿè®¡
        param_counts = self._analyze_trainable_parameters()
        
        total_trainable = sum(param_counts.values())
        print(f"  âœ… æ€»å¯è®­ç»ƒå‚æ•°: {total_trainable:,}")
        
        if total_trainable < 1000:
            logger.error("âŒ å¯è®­ç»ƒå‚æ•°è¿‡å°‘ï¼Œå¯èƒ½é…ç½®æœ‰è¯¯!")
            return float('inf'), save_path
        
        total_params_count = sum(p.numel() for p in self.model.parameters())
        print(f"  æ¨¡å‹æ€»å‚æ•°: {total_params_count:,}")
        print(f"  é˜¶æ®µ1è®­ç»ƒæ¯”ä¾‹: {total_trainable/total_params_count*100:.1f}%")
        
        if len(trainable_params) == 0:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯è®­ç»ƒçš„å‚æ•°!")
            return float('inf'), save_path
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate, weight_decay=0.01)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
        
        # è®­ç»ƒå¾ªç¯...
        best_val_loss = float('inf')
        patience = 15
        patience_counter = 0
        
        self.stage1_losses = {'train': [], 'val': []}
        
        for epoch in range(epochs):
            print(f"\n--- Stage1 Epoch {epoch+1}/{epochs} ---")
            
            # è®­ç»ƒ
            train_loss = self._train_contrastive_epoch(train_loader, optimizer)
            self.stage1_losses['train'].append(train_loss)
            print(f"è®­ç»ƒå¯¹æ¯”æŸå¤±: {train_loss:.4f}")
            
            # éªŒè¯
            val_loss = self._validate_contrastive_epoch(val_loader)
            self.stage1_losses['val'].append(val_loss)
            print(f"éªŒè¯å¯¹æ¯”æŸå¤±: {val_loss:.4f}")
            
            scheduler.step()
            
            # æ—©åœå’Œä¿å­˜
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # ä¿å­˜ç¼–ç å™¨çŠ¶æ€
                encoder_state = {
                    'patch_extractor': self.model.patch_extractor.state_dict(),
                    'eeg_encoder': self.model.eeg_encoder.state_dict(),
                    'eeg_projection': self.model.eeg_projection.state_dict(),
                    'text_encoder': self.model.text_encoder.state_dict(),
                    'text_projection': self.model.text_projection.state_dict(),
                    'epoch': epoch,
                    'val_loss': val_loss,
                }
                torch.save(encoder_state, save_path)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³ç¼–ç å™¨: {save_path}")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"â¹ï¸ æ—©åœè§¦å‘")
                    break
        
        print(f"\nâœ… é˜¶æ®µ1å®Œæˆ! æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
        return best_val_loss, save_path
    
    def stage2_decoder_finetuning(self, train_loader, val_loader, encoder_path, epochs=25, 
                                 learning_rate=2e-5, save_path="stage2_decoder_finetuned.pth"):
        """é˜¶æ®µ2: å†»ç»“ç¼–ç å™¨ï¼Œå¾®è°ƒBARTè§£ç å™¨"""
        print("\n" + "="*60)
        print("ğŸ”’ é˜¶æ®µ2: å†»ç»“EEGç¼–ç å™¨ï¼Œå¾®è°ƒBARTè§£ç å™¨")
        print("ğŸ“‹ ç­–ç•¥: ä½¿ç”¨é¢„è®­ç»ƒçš„EEGç‰¹å¾ï¼Œè®©BARTå­¦ä¼šç”Ÿæˆå¯¹åº”æ–‡æœ¬")
        print("="*60)
        
        # åŠ è½½é¢„è®­ç»ƒçš„ç¼–ç å™¨
        encoder_state = torch.load(encoder_path, map_location='cpu')
        self.model.patch_extractor.load_state_dict(encoder_state['patch_extractor'])
        self.model.eeg_encoder.load_state_dict(encoder_state['eeg_encoder'])
        self.model.eeg_projection.load_state_dict(encoder_state['eeg_projection'])
        self.model.text_encoder.load_state_dict(encoder_state['text_encoder'])
        self.model.text_projection.load_state_dict(encoder_state['text_projection'])
        print(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒç¼–ç å™¨: {encoder_path}")
        
        # âœ… ä½¿ç”¨æ¨¡å‹çš„é…ç½®æ–¹æ³•
        print("ğŸ”§ é…ç½®é˜¶æ®µ2å‚æ•°çŠ¶æ€...")
        self.model.configure_for_stage2(freeze_decoder=False, freeze_eeg_encoder=True)
        
        # âœ… æ”¶é›†å¯è®­ç»ƒå‚æ•°
        trainable_params = [p for p in self.model.parameters() if p.requires_grad]
        
        print(f"ğŸ“Š é˜¶æ®µ2å¯è®­ç»ƒå‚æ•°æ•°é‡: {len(trainable_params)}")
        
        if len(trainable_params) == 0:
            logger.error("âŒ æ²¡æœ‰å¯è®­ç»ƒçš„å‚æ•°!")
            return float('inf')
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate, weight_decay=0.01)
        
        # ä½¿ç”¨é€‚åˆå¾®è°ƒçš„è°ƒåº¦å™¨
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', patience=5, factor=0.5, min_lr=1e-7
        )
        
        # ç»Ÿè®¡å‚æ•°
        trainable_params_count = sum(p.numel() for p in trainable_params)
        total_params_count = sum(p.numel() for p in self.model.parameters())
        
        print(f"ğŸ“Š é˜¶æ®µ2å‚æ•°ç»Ÿè®¡:")
        print(f"  æ€»å‚æ•°: {total_params_count:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params_count:,}")
        print(f"  è®­ç»ƒæ¯”ä¾‹: {trainable_params_count/total_params_count*100:.1f}%")
        
        # è®­ç»ƒå¾ªç¯...
        best_val_loss = float('inf')
        patience = 10
        patience_counter = 0
        
        self.stage2_losses = {'train': [], 'val': []}
        
        for epoch in range(epochs):
            print(f"\n--- Stage2 Decoder Finetuning Epoch {epoch+1}/{epochs} ---")
            
            # è®­ç»ƒ
            train_loss = self._train_generation_epoch(train_loader, optimizer)
            self.stage2_losses['train'].append(train_loss)
            print(f"è®­ç»ƒç”ŸæˆæŸå¤±: {train_loss:.4f}")
            
            # éªŒè¯
            val_loss = self._validate_generation_epoch(val_loader)
            self.stage2_losses['val'].append(val_loss)
            print(f"éªŒè¯ç”ŸæˆæŸå¤±: {val_loss:.4f}")
            
            # è°ƒåº¦å™¨æ›´æ–°
            scheduler.step(val_loss)
            current_lr = optimizer.param_groups[0]['lr']
            print(f"å½“å‰å­¦ä¹ ç‡: {current_lr:.2e}")
            
            # æ¯3ä¸ªepochæµ‹è¯•ç”Ÿæˆæ•ˆæœ
            if (epoch + 1) % 3 == 0:
                print("\nğŸ“ ç”Ÿæˆæ ·æœ¬æµ‹è¯•:")
                self._test_generation(val_loader, num_samples=3)
            
            # æ—©åœå’Œä¿å­˜
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(self.model.state_dict(), save_path)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³è§£ç å™¨æ¨¡å‹: {save_path}")
            else:
                patience_counter += 1
                print(f"ğŸ“Š éªŒè¯æŸå¤±æœªæ”¹å–„ ({patience_counter}/{patience})")
                if patience_counter >= patience:
                    print(f"â¹ï¸ æ—©åœè§¦å‘ (å¾®è°ƒå®Œæˆ)")
                    break
        
        print(f"\nâœ… é˜¶æ®µ2è§£ç å™¨å¾®è°ƒå®Œæˆ! æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
        return best_val_loss
    
    def _analyze_trainable_parameters(self):
        """åˆ†æå¯è®­ç»ƒå‚æ•°åˆ†å¸ƒ"""
        param_counts = {}
        
        # åˆ†æå„ç»„ä»¶å‚æ•°
        components = {
            'patch_extractor': self.model.patch_extractor,
            'eeg_encoder': self.model.eeg_encoder,
            'eeg_projection': self.model.eeg_projection,
            'text_encoder': self.model.text_encoder,
            'text_projection': self.model.text_projection,
            'bart_encoder': self.model.bart.model.encoder,
            'bart_decoder': self.model.bart.model.decoder,
            'bart_lm_head': self.model.bart.lm_head,
        }
        
        print(f"\nğŸ“Š è¯¦ç»†å‚æ•°åˆ†æ:")
        for name, component in components.items():
            trainable = sum(p.numel() for p in component.parameters() if p.requires_grad)
            total = sum(p.numel() for p in component.parameters())
            status = "ğŸ”“" if trainable > 0 else "ğŸ”’"
            print(f"  {status} {name}: {trainable:,} / {total:,} å¯è®­ç»ƒ")
            param_counts[name] = trainable
        
        return param_counts
    
    def _train_contrastive_epoch(self, train_loader, optimizer):
        """é˜¶æ®µ1è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0
        
        progress_bar = tqdm(train_loader, desc="Stage1 Contrastive")
        
        for batch in progress_bar:
            optimizer.zero_grad()
            
            try:
                outputs = self.model(
                    eeg_data=batch['eeg'],
                    text_data=batch['text'],
                    tokenizer=self.tokenizer,
                    mode="contrastive"
                )
                
                loss = outputs['loss']
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})
                
            except Exception as e:
                logger.error(f"è®­ç»ƒæ‰¹æ¬¡å‡ºé”™: {e}")
                continue
        
        return total_loss / num_batches if num_batches > 0 else float('inf')
    
    def _train_generation_epoch(self, train_loader, optimizer):
        """é˜¶æ®µ2è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0
        
        progress_bar = tqdm(train_loader, desc="Stage2 Generation")
        
        for batch in progress_bar:
            optimizer.zero_grad()
            
            try:
                outputs = self.model(
                    eeg_data=batch['eeg'],
                    text_data=batch['text'],
                    tokenizer=self.tokenizer,
                    mode="generation_training"
                )
                
                loss = outputs['loss']
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})
                
            except Exception as e:
                logger.error(f"è®­ç»ƒæ‰¹æ¬¡å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        return total_loss / num_batches if num_batches > 0 else float('inf')
    
    def _validate_contrastive_epoch(self, val_loader):
        """é˜¶æ®µ1éªŒè¯"""
        self.model.eval()
        total_loss = 0
        num_batches = 0
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="Stage1 Validation"):
                try:
                    outputs = self.model(
                        eeg_data=batch['eeg'],
                        text_data=batch['text'],
                        tokenizer=self.tokenizer,
                        mode="contrastive"
                    )
                    
                    loss = outputs['loss']
                    total_loss += loss.item()
                    num_batches += 1
                    
                except Exception as e:
                    continue
        
        return total_loss / num_batches if num_batches > 0 else float('inf')
    
    def _validate_generation_epoch(self, val_loader):
        """é˜¶æ®µ2éªŒè¯"""
        self.model.eval()
        total_loss = 0
        num_batches = 0
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="Stage2 Validation"):
                try:
                    outputs = self.model(
                        eeg_data=batch['eeg'],
                        text_data=batch['text'],
                        tokenizer=self.tokenizer,
                        mode="generation_training"
                    )
                    
                    loss = outputs['loss']
                    total_loss += loss.item()
                    num_batches += 1
                    
                except Exception as e:
                    logger.error(f"éªŒè¯æ‰¹æ¬¡å‡ºé”™: {e}")
                    continue
        
        return total_loss / num_batches if num_batches > 0 else float('inf')
    
    def _test_generation(self, val_loader, num_samples=3):
        """æµ‹è¯•ç”Ÿæˆæ•ˆæœ - å¢å¼ºè°ƒè¯•ä¿¡æ¯"""
        self.model.eval()
        samples_generated = 0
        
        with torch.no_grad():
            for batch in val_loader:
                if samples_generated >= num_samples:
                    break
                
                eeg_data = batch['eeg'][:min(num_samples - samples_generated, len(batch['eeg']))]
                original_texts = batch['text'][:len(eeg_data)]
                ids = batch['ids'][:len(eeg_data)]
                
                try:
                    # âœ… å¢åŠ è°ƒè¯•ä¿¡æ¯
                    print(f"\nè°ƒè¯•ä¿¡æ¯:")
                    print(f"  æ‰¹æ¬¡å¤§å°: {len(eeg_data)}")
                    print(f"  EEGæ•°æ®ç±»å‹: {type(eeg_data[0])}")
                    if hasattr(eeg_data[0], 'shape'):
                        print(f"  EEGå½¢çŠ¶: {eeg_data[0].shape}")
                    
                    generated_texts = self.model.generate_text(
                        eeg_data=eeg_data,
                        tokenizer=self.tokenizer,
                        max_length=32,
                        num_beams=4
                    )
                    
                    for i, (gen_text, orig_text, sample_id) in enumerate(zip(generated_texts, original_texts, ids)):
                        print(f"  æ ·æœ¬ {samples_generated + i + 1} (ID: {sample_id}):")
                        print(f"    åŸæ–‡: {orig_text}")
                        print(f"    ç”Ÿæˆ: {gen_text}")
                        
                        # âœ… æ£€æŸ¥ç”Ÿæˆæ–‡æœ¬çš„ç‰¹å¾
                        gen_tokens = gen_text.split()
                        if len(set(gen_tokens)) == 1:  # æ‰€æœ‰tokenéƒ½ç›¸åŒ
                            print(f"    âš ï¸  è­¦å‘Š: ç”Ÿæˆæ–‡æœ¬åªå«å•ä¸€token!")
                        if len(gen_tokens) < 3:
                            print(f"    âš ï¸  è­¦å‘Š: ç”Ÿæˆæ–‡æœ¬è¿‡çŸ­!")
                        
                    samples_generated += len(generated_texts)
                    
                except Exception as e:
                    print(f"  ç”Ÿæˆå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    break
    
    def plot_training_history(self, save_dir):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        plt.figure(figsize=(15, 5))
        
        # é˜¶æ®µ1æŸå¤±
        if self.stage1_losses['train']:
            plt.subplot(1, 3, 1)
            epochs1 = range(1, len(self.stage1_losses['train']) + 1)
            plt.plot(epochs1, self.stage1_losses['train'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
            plt.plot(epochs1, self.stage1_losses['val'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
            plt.xlabel('Epoch')
            plt.ylabel('å¯¹æ¯”æŸå¤±')
            plt.title('é˜¶æ®µ1: å¯¹æ¯”å­¦ä¹ è®­ç»ƒ')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # é˜¶æ®µ2æŸå¤±
        if self.stage2_losses['train']:
            plt.subplot(1, 3, 2)
            epochs2 = range(1, len(self.stage2_losses['train']) + 1)
            plt.plot(epochs2, self.stage2_losses['train'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
            plt.plot(epochs2, self.stage2_losses['val'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
            plt.xlabel('Epoch')
            plt.ylabel('ç”ŸæˆæŸå¤±')
            plt.title('é˜¶æ®µ2: ç”Ÿæˆè®­ç»ƒ')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # å¯¹æ¯”ä¸¤ä¸ªé˜¶æ®µ
        if self.stage1_losses['val'] and self.stage2_losses['val']:
            plt.subplot(1, 3, 3)
            stage1_min = min(self.stage1_losses['val'])
            stage2_min = min(self.stage2_losses['val'])
            plt.bar(['é˜¶æ®µ1\n(å¯¹æ¯”æŸå¤±)', 'é˜¶æ®µ2\n(ç”ŸæˆæŸå¤±)'], [stage1_min, stage2_min], 
                   color=['skyblue', 'lightcoral'], alpha=0.7)
            plt.ylabel('æœ€ä½³éªŒè¯æŸå¤±')
            plt.title('ä¸¤é˜¶æ®µå¯¹æ¯”')
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plot_path = save_dir / 'two_stage_training.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"è®­ç»ƒå†å²å›¾ä¿å­˜åˆ°: {plot_path}")

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # é…ç½®å‚æ•°
    config = {
        'csv_file': 'additional_data/subject1_gxy_0328/gxy_0328.csv',
        'eeg_dir': 'additional_data/subject1_gxy_0328/',
        'batch_size': 4,
        'test_size': 0.2,
        'random_state': 42,
        
        # âœ… ä¿®æ”¹ï¼šè·³è¿‡é˜¶æ®µ1ï¼Œç›´æ¥è®­ç»ƒé˜¶æ®µ2
        'skip_stage1': True,  # è·³è¿‡é˜¶æ®µ1
        'stage1_model_path': 'two_stage_bart_encoder_20250710_131923/stage1_encoder.pth',  # âœ… æ‚¨çš„é˜¶æ®µ1æ¨¡å‹è·¯å¾„
        
        # é˜¶æ®µ1å‚æ•°ï¼ˆå¦‚æœéœ€è¦ï¼‰
        'stage1_epochs': 30,
        'stage1_lr': 1e-4,
        
        # é˜¶æ®µ2å‚æ•°ï¼šå†»ç»“ç¼–ç å™¨ï¼Œå¾®è°ƒè§£ç å™¨
        'stage2_epochs': 25,
        'stage2_lr': 2e-5,  # ç¨å¾®å°ä¸€ç‚¹çš„å­¦ä¹ ç‡ç”¨äºå¾®è°ƒ
        
        'save_dir': f'stage2_only_bart_decoder_{datetime.now().strftime("%Y%m%d_%H%M%S")}'  # âœ… ä¿®æ”¹ç›®å½•å
    }
    
    logger.info("=== EEG-to-Text é˜¶æ®µ2è®­ç»ƒï¼ˆBARTè§£ç å™¨å¾®è°ƒï¼‰ ===")
    logger.info("ğŸ¯ è®­ç»ƒç­–ç•¥:")
    logger.info("  ğŸ”„ è·³è¿‡é˜¶æ®µ1ï¼Œç›´æ¥åŠ è½½é¢„è®­ç»ƒç¼–ç å™¨")
    logger.info("  ğŸ”’ é˜¶æ®µ2: å†»ç»“EEGç¼–ç å™¨ï¼Œå¾®è°ƒBARTè§£ç å™¨")
    logger.info("  ğŸ“ æ–‡æœ¬ç”Ÿæˆå™¨: BARTè§£ç å™¨ (fnlp/bart-base-chinese)")
    
    logger.info("é…ç½®å‚æ•°:")
    for key, value in config.items():
        logger.info(f"  {key}: {value}")
    
    # âœ… æ£€æŸ¥é˜¶æ®µ1æ¨¡å‹è·¯å¾„
    if config['skip_stage1']:
        stage1_path = config['stage1_model_path']
        if not os.path.exists(stage1_path):
            logger.error(f"âŒ é˜¶æ®µ1æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {stage1_path}")
            logger.info("è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼Œæˆ–è®¾ç½® skip_stage1=False é‡æ–°è®­ç»ƒé˜¶æ®µ1")
            return
        else:
            logger.info(f"âœ… æ‰¾åˆ°é˜¶æ®µ1æ¨¡å‹: {stage1_path}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists(config['csv_file']):
        logger.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {config['csv_file']}")
        return
    
    if not os.path.exists(config['eeg_dir']):
        logger.error(f"EEGç›®å½•ä¸å­˜åœ¨: {config['eeg_dir']}")
        return
    
    # âœ… æ£€æŸ¥EEGç›®å½•å†…å®¹
    logger.info(f"\nğŸ” è¯¦ç»†æ£€æŸ¥EEGç›®å½•å†…å®¹:")
    try:
        files = os.listdir(config['eeg_dir'])
        npy_files = [f for f in files if f.endswith('.npy')]
        logger.info(f"  æ€»æ–‡ä»¶æ•°: {len(files)}")
        logger.info(f"  .npyæ–‡ä»¶æ•°: {len(npy_files)}")
        
        if len(npy_files) > 0:
            logger.info(f"  æ–‡ä»¶åç¤ºä¾‹: {npy_files[:5]}")
        else:
            logger.error("  âŒ æ²¡æœ‰æ‰¾åˆ°.npyæ–‡ä»¶!")
            return
    except Exception as e:
        logger.error(f"è¯»å–EEGç›®å½•å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = Path(config['save_dir'])
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # âœ… åˆå§‹åŒ–tokenizer
    logger.info("åˆå§‹åŒ–tokenizer...")
    try:
        from transformers import AutoTokenizer
        tokenizer = AutoTokenizer.from_pretrained('fnlp/bart-base-chinese')
        logger.info(f"âœ… æˆåŠŸåŠ è½½tokenizer: {type(tokenizer).__name__}")
    except Exception as e:
        logger.warning(f"AutoTokenizeråŠ è½½å¤±è´¥: {e}")
        try:
            from transformers import BertTokenizer
            tokenizer = BertTokenizer.from_pretrained('fnlp/bart-base-chinese')
            logger.info("âœ… æˆåŠŸåŠ è½½BertTokenizer (fnlp/bart-base-chinese)")
        except Exception as e2:
            logger.warning(f"BertTokenizeråŠ è½½å¤±è´¥: {e2}")
            from transformers import BertTokenizer
            tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
            logger.info("âœ… ä½¿ç”¨å¤‡ç”¨BertTokenizer (bert-base-chinese)")
    
    # åˆ›å»ºæ•°æ®é›†
    logger.info("åˆ›å»ºæ•°æ®é›†...")
    full_dataset = EEGTextDataset(
        csv_file=config['csv_file'],
        eeg_dir=config['eeg_dir'],
        tokenizer=tokenizer
    )
    
    if len(full_dataset) == 0:
        logger.error("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒ!")
        return
    
    logger.info(f"æ€»æ•°æ®æ ·æœ¬: {len(full_dataset)}")
    
    # åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯é›†
    train_indices, val_indices = train_test_split(
        range(len(full_dataset)), 
        test_size=config['test_size'], 
        random_state=config['random_state']
    )
    
    train_dataset = Subset(full_dataset, train_indices)
    val_dataset = Subset(full_dataset, val_indices)
    
    logger.info(f"è®­ç»ƒæ ·æœ¬: {len(train_dataset)}, éªŒè¯æ ·æœ¬: {len(val_dataset)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=0
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        collate_fn=collate_fn,
        num_workers=0
    )
    
    # åˆ›å»ºæ¨¡å‹
    logger.info("åˆ›å»ºEEG-to-Textæ¨¡å‹...")
    logger.info("  ğŸ“ æ–‡æœ¬ç¼–ç å™¨: BARTç¼–ç å™¨ (fnlp/bart-base-chinese)")
    logger.info("  ğŸ“ æ–‡æœ¬ç”Ÿæˆå™¨: BARTè§£ç å™¨ (fnlp/bart-base-chinese)")
    logger.info("  ğŸ”„ ç¼–ç å™¨å’Œè§£ç å™¨ä½¿ç”¨åŒä¸€ä¸ªBARTæ¨¡å‹")
    
    model = create_contrastive_model(
        bart_model_name="fnlp/bart-base-chinese",
        patch_dim=256,
        feature_dim=768,
        target_channels=66,
        target_length=4000,
        temperature=0.07
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    trainer = TwoStageTrainer(model, tokenizer, device)
    
    # âœ… æ ¹æ®é…ç½®å†³å®šæ˜¯å¦è·³è¿‡é˜¶æ®µ1
    if config['skip_stage1']:
        logger.info("\n" + "="*60)
        logger.info("ğŸ”„ è·³è¿‡é˜¶æ®µ1ï¼Œç›´æ¥è¿›å…¥é˜¶æ®µ2è®­ç»ƒ")
        logger.info(f"ğŸ“¥ å°†ä½¿ç”¨é¢„è®­ç»ƒç¼–ç å™¨: {config['stage1_model_path']}")
        logger.info("="*60)
        
        # ç›´æ¥ä½¿ç”¨æä¾›çš„é˜¶æ®µ1æ¨¡å‹è·¯å¾„
        stage1_encoder_path = config['stage1_model_path']
        stage1_loss = 0.0  # å ä½å€¼
        
    else:
        # å¦‚æœä¸è·³è¿‡ï¼Œæ‰§è¡Œé˜¶æ®µ1è®­ç»ƒ
        logger.info("\n" + "="*60)
        logger.info("ğŸ”¥ å¼€å§‹é˜¶æ®µ1: å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒEEGç¼–ç å™¨")
        logger.info("ğŸ“‹ ç›®æ ‡: å­¦ä¹ EEGä¿¡å·ä¸ä¸­æ–‡æ–‡æœ¬çš„å¯¹åº”å…³ç³»")
        logger.info("ğŸ¯ ä½¿ç”¨BARTç¼–ç å™¨è¿›è¡Œæ–‡æœ¬ç‰¹å¾æå–")
        logger.info("="*60)
        
        stage1_encoder_path = save_dir / 'stage1_encoder.pth'
        stage1_loss, _ = trainer.stage1_contrastive_training(
            train_loader=train_loader,
            val_loader=val_loader,
            epochs=config['stage1_epochs'],
            learning_rate=config['stage1_lr'],
            save_path=stage1_encoder_path
        )
    
    # âœ… é˜¶æ®µ2ï¼šå†»ç»“ç¼–ç å™¨ï¼Œå¾®è°ƒè§£ç å™¨
    logger.info("\n" + "="*60)
    logger.info("ğŸ”’ å¼€å§‹é˜¶æ®µ2: å†»ç»“EEGç¼–ç å™¨ï¼Œå¾®è°ƒBARTè§£ç å™¨")
    logger.info("ğŸ“‹ ç›®æ ‡: è®©BARTè§£ç å™¨å­¦ä¼šä»é¢„è®­ç»ƒEEGç‰¹å¾ç”Ÿæˆä¸­æ–‡æ–‡æœ¬")
    logger.info("ğŸ¯ å†»ç»“BARTç¼–ç å™¨å’ŒEEGç¼–ç å™¨ï¼Œåªè®­ç»ƒBARTè§£ç å™¨")
    logger.info(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒç¼–ç å™¨: {stage1_encoder_path}")
    logger.info("="*60)
    
    stage2_loss = trainer.stage2_decoder_finetuning(
        train_loader=train_loader,
        val_loader=val_loader,
        encoder_path=stage1_encoder_path,
        epochs=config['stage2_epochs'],
        learning_rate=config['stage2_lr'],
        save_path=save_dir / 'stage2_decoder_finetuned.pth'
    )
    
    # ç»˜åˆ¶è®­ç»ƒå†å²ï¼ˆå¦‚æœæœ‰é˜¶æ®µ1æ•°æ®ï¼‰
    if not config['skip_stage1']:
        trainer.plot_training_history(save_dir)
    else:
        # åªç»˜åˆ¶é˜¶æ®µ2çš„è®­ç»ƒå†å²
        if trainer.stage2_losses['train']:
            plt.figure(figsize=(10, 5))
            
            plt.subplot(1, 2, 1)
            epochs2 = range(1, len(trainer.stage2_losses['train']) + 1)
            plt.plot(epochs2, trainer.stage2_losses['train'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
            plt.plot(epochs2, trainer.stage2_losses['val'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
            plt.xlabel('Epoch')
            plt.ylabel('ç”ŸæˆæŸå¤±')
            plt.title('é˜¶æ®µ2: BARTè§£ç å™¨å¾®è°ƒ')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            plt.subplot(1, 2, 2)
            stage2_min = min(trainer.stage2_losses['val'])
            plt.bar(['é˜¶æ®µ2\n(ç”ŸæˆæŸå¤±)'], [stage2_min], 
                   color=['lightcoral'], alpha=0.7)
            plt.ylabel('æœ€ä½³éªŒè¯æŸå¤±')
            plt.title('è®­ç»ƒç»“æœ')
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plot_path = save_dir / 'stage2_training.png'
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.show()
            logger.info(f"é˜¶æ®µ2è®­ç»ƒå†å²å›¾ä¿å­˜åˆ°: {plot_path}")
    
    # ä¿å­˜è®­ç»ƒç»“æœ
    results = {
        'stage1_loss': stage1_loss,
        'stage2_loss': stage2_loss,
        'stage1_history': trainer.stage1_losses if not config['skip_stage1'] else {},
        'stage2_history': trainer.stage2_losses,
        'config': config,
        'training_strategy': 'stage2_only_bart_decoder_finetuning',
        'stage1_model_used': stage1_encoder_path,
        'models': {
            'text_encoder': 'BARTç¼–ç å™¨ (fnlp/bart-base-chinese)',
            'text_generator': 'BARTè§£ç å™¨ (fnlp/bart-base-chinese)',
            'unified_model': 'fnlp/bart-base-chinese'
        },
        'timestamp': datetime.now().isoformat()
    }
    
    results_path = save_dir / 'training_results.json'
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # âœ… å®Œæˆä¿¡æ¯
    if config['skip_stage1']:
        logger.info(f"\nğŸ‰ é˜¶æ®µ2 BARTè§£ç å™¨å¾®è°ƒå®Œæˆ!")
        logger.info(f"ğŸ“¥ ä½¿ç”¨çš„é˜¶æ®µ1ç¼–ç å™¨: {stage1_encoder_path}")
        logger.info(f"ğŸ“Š é˜¶æ®µ2 (BARTè§£ç å™¨å¾®è°ƒ): {stage2_loss:.4f}")
    else:
        logger.info(f"\nğŸ‰ ä¸¤é˜¶æ®µBARTç¼–ç å™¨è®­ç»ƒå®Œæˆ!")
        logger.info(f"ğŸ“Š é˜¶æ®µ1 (EEGç¼–ç å™¨é¢„è®­ç»ƒ): {stage1_loss:.4f}")
        logger.info(f"ğŸ“Š é˜¶æ®µ2 (BARTè§£ç å™¨å¾®è°ƒ): {stage2_loss:.4f}")
    
    logger.info(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {save_dir}")
    logger.info(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹: {save_dir / 'stage2_decoder_finetuned.pth'}")
    logger.info(f"ğŸ”„ ä½¿ç”¨ç»Ÿä¸€çš„BARTæ¨¡å‹: fnlp/bart-base-chinese")
    
    # âœ… æµ‹è¯•æœ€ç»ˆæ¨¡å‹
    logger.info("\nğŸ§ª æµ‹è¯•æœ€ç»ˆæ¨¡å‹ç”Ÿæˆæ•ˆæœ:")
    trainer._test_generation(val_loader, num_samples=5)

if __name__ == "__main__":
    main()
